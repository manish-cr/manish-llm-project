{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain                                0.1.16\n",
      "langchain-chroma                         0.1.0\n",
      "langchain-community                      0.0.34\n",
      "langchain-core                           0.1.45\n",
      "langchain-openai                         0.1.3\n",
      "langchain-text-splitters                 0.0.1\n"
     ]
    }
   ],
   "source": [
    "! pip list | findstr langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "# prompt = ChatPromptTemplate.from_messages([\n",
    "#     (\"system\", \"\"\"\n",
    "#      You are familiar with this person Manish. Here are some information that you know about him:\n",
    "#      Name: Manish\n",
    "#      Occupation: revenue operations intern at SAP\n",
    "#      job scope: sales support via excel consolidation\n",
    "#      reports to: Magdalene Usada (also known as Maggy)\n",
    "#      colleagues: [\"Drae Ramirez\", \"Daphne Koh\", \"Lindsey\", \"Monte Reynaldo\", \"Elizabeth\"]\n",
    "#      STAR batch intern: 6\n",
    "#      STAR batch: 2024\n",
    "#      STAR batch mentor: Irene and Jean\n",
    "#      STAR batch colleagues: ['Saniya', 'Jia Ning', \"Ren Yi\", \"Saieesh\", \"Jean Tay\", \"Boyi\", \"Ting Fung\", \"Khai\"]\n",
    "#      Onboarding date: Dec 2023\n",
    "#      Official start date: Jan 2024\n",
    "#      year of graduation and end date: May 2025\n",
    "#      favorite movie: Om Shanti Om\n",
    "#      languages: benagli, english\n",
    "#      favorite book: The Millionare Next Door\n",
    "#      favorite song: House of the rising sun\n",
    "#      favorite TV series: Breaking Bad\n",
    "#      next rotations of interest: generative AI engineer, Data Analyst Signavio, Datahub Digital Intelligence Analyst\n",
    "#      Fan: Lex Friedman\n",
    "#      Age: 24\n",
    "#      Friends: [\"Samuel, Barnabas\"]\n",
    "#      Interests and hobbies: coding, reading, working out\n",
    "#      Favorite food: Ramen\n",
    "#      guilty pleasure: Ramen\n",
    "#      pet peeves: people who don't listen\n",
    "#      Favorite color: Blue\n",
    "#      Aspiration: Machine Learning Engineer at SAP\n",
    "#      Lives in: Singapore (Sengkang)\n",
    "#      Gender and sex: Male\n",
    "#      Race: Bengali\n",
    "#      Religion: Free Thinker\n",
    "#      Height: 175 cm\n",
    "#      Weight: 68 kg\n",
    "#      Course of study: Data Science and Analytics\n",
    "#      Specialization: Operations Research\n",
    "#      Motto: \"Do what you love, love what you do\"\n",
    "#      National Service Status: Completed (Singapore Police Force, Transport Command, 1st Sergeant)\n",
    "#      Reservist Status: 2nd Cycle\n",
    "#      If there is anything that you don't know about him, you can ask him.\n",
    "#      When prompted for an answer to a question that you don't know, you can say \"I don't know\".\n",
    "#      \"\"\"),\n",
    "#     (\"user\", \"{input}\")\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def handle_user_input():\n",
    "    \n",
    "#     while True:\n",
    "#         input_str = input(\"Enter your message: \")\n",
    "#         response = chain.invoke({\"input\": input_str})\n",
    "#         print(response)\n",
    "#         if(input_str == \"exit\"):\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Manish chatbot is ready. exit the chatbot by typing 'exit'\")\n",
    "# handle_user_input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alt approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "path = \"../data/general_data.txt\"\n",
    "loader = TextLoader(path)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document chunking\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the vector store\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "db = Chroma.from_documents(chunks, OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retreival\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmented\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Manish's favorite food is Ramen.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generation\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "rag_chain = (\n",
    "    {\"context\": retriever,  \"question\": RunnablePassthrough()} \n",
    "    | prompt \n",
    "    | llm\n",
    "    | StrOutputParser() \n",
    ")\n",
    "query = \"What is Manish's favorite food?\"\n",
    "rag_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_user_input():\n",
    "    \n",
    "    while True:\n",
    "        input_str = input(\"Enter your message: \")\n",
    "        if(input_str == \"exit\"):\n",
    "            break\n",
    "        response = rag_chain.invoke(input_str)\n",
    "        print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manish chatbot is ready. Exit the chatbot by typing 'exit'\n"
     ]
    }
   ],
   "source": [
    "print(\"Manish chatbot is ready. Exit the chatbot by typing 'exit'\")\n",
    "handle_user_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
